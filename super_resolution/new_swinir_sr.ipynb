{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"new_swinir_sr.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyO8Lxgsi+dnifMI6KK6IbFk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IA6QBYk71KBh"},"source":["# DATA Load\n","kaggle에 업로드되어 있는 danbooru2020 dataset을 사용.<br>\n","kaggle: https://www.kaggle.com/muoncollider/danbooru2020"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POxwh0IanN3D"},"outputs":[],"source":["!pip install kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LU4ptvm43fbH"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9flPMvLrnT2-"},"outputs":[],"source":["from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upPm2luWnu7t"},"outputs":[],"source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbscmoKvx92X"},"outputs":[],"source":["!kaggle datasets download -d muoncollider/danbooru2020"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Ztck704yDf6"},"outputs":[],"source":["!unzip danbooru2020.zip -d /content/test_folder"]},{"cell_type":"markdown","metadata":{"id":"TvW0q5qi1Mi3"},"source":["# MODEL architecture\n","model architecture는 Swinir 모델 사용<br>\n","model 설명: https://github.com/alzoqm/transformer_model/tree/main/models/swinIR\n"]},{"cell_type":"code","source":["%cd drive/MyDrive/ColabNotebooks/project/super_resolution"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCVHTPV9rIn6","executionInfo":{"status":"ok","timestamp":1644297387884,"user_tz":-540,"elapsed":634,"user":{"displayName":"nais y","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02059557756502258442"}},"outputId":"0854e6aa-2e67-4e17-87b8-dd0ea31bd651"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/project/super_resolution/model\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIfNg_XOrtah","executionInfo":{"status":"ok","timestamp":1644297388198,"user_tz":-540,"elapsed":315,"user":{"displayName":"nais y","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02059557756502258442"}},"outputId":"8cab19cd-4e02-4419-f5f2-f816bcb0b58a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["new_swinir_sr.ipynb  save_weights\t   swinir_tf.py\n","__pycache__\t     SwinIR_SR_test.ipynb\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","import os\n","import cv2\n","import tqdm\n","import torch\n","import math\n","import h5py\n","import imageio\n","import random\n","\n","from tqdm import tqdm\n","\n","from model import swinir_tf as swinir #기존 model load"],"metadata":{"id":"3kjZY42vrSz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#####PARAMETERS######\n","IMG_SIZE = 64\n","PATCH_SIZE = 1\n","IN_CHANS = 3\n","EMB_SIZE = 180\n","DEPTHS = [6, 6, 6, 6]\n","NUM_HEADS = [6, 6, 6, 6]\n","WINDOW_SIZE = 4\n","MLP_RATIO = 4\n","QKV_BIAS = True\n","DROP_RATE = 0.1\n","ATTN_DROP_RATE = 0.1\n","DROP_PATH_RATE = 0.1\n","APE = False\n","PATCH_NORM = True\n","UPSCALE = 2\n","IMG_RANGE = 255\n","RESI_CONNECTION = '3conv'"],"metadata":{"id":"5ofmP4u5Aijg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aVCE-cTdOlX6"},"source":["# TPU 학습 조성 및 drive 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLx-iIh-08Ko"},"outputs":[],"source":["resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","\n","strategy = tf.distribute.TPUStrategy(resolver)"]},{"cell_type":"markdown","metadata":{"id":"pgKTZgI_PAAv"},"source":["# DATA preprocessing\n","colab tpu를 사용하더라도 512 x 512 이미지를 한번에 학습을 할 수가 없기에 이미지를 64 x 64로 나누어서 학습.<br>\n","한번에 모든 데이터를 불러오기에는 데이터 크기에 비해 ram이 부족하므로 데이터를 나누어서 불러올 수 있는 함수를 생성(dataload_function).<br>\n","이 함수는 아래의 training 상황에서 epoch 값에 해당하는 데이터를 불러옴."]},{"cell_type":"code","source":["def image_slice(image, patch_size):\n","  slice_list = []\n","  height, width = image.shape[0], image.shape[1]\n","  height_slice = height // patch_size[0]\n","  width_slice = width // patch_size[1]\n","\n","  for i in range(height_slice):\n","    for j in range(width_slice):\n","      slice_img = image[i * patch_size[0] : (i+1) * patch_size[0], j * patch_size[1] : (j+1) * patch_size[1], :]\n","      slice_img = np.array(slice_img)\n","      slice_list.append(slice_img)\n","\n","  return np.array(slice_list)"],"metadata":{"id":"DpEQskt7qzi5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5d37ARJC0-5O"},"outputs":[],"source":["danbooru_path = '/content/test_folder'\n","danbooru_list = os.listdir(danbooru_path)\n","accl = []\n","\n","for danbooru in danbooru_list:\n","  data = os.listdir(danbooru_path + '/' + danbooru)\n","  accl.append(data)\n","\n","def dataload_function(cnt, accl, danbooru_path, danbooru_list):\n","  all_img_SR = []\n","  all_img_LR = []\n","  for idx, line in enumerate(accl):\n","    if idx == cnt:\n","      for pic in line:\n","        image_rgb_SR = cv2.imread(danbooru_path + '/' + danbooru_list[idx] + '/' + pic, cv2.IMREAD_COLOR)\n","        image_rgb_LR = cv2.resize(image_rgb_SR, (256, 256)) #LR 이미지 크기\n","\n","        image_rgb_SR = image_slice(image_rgb_SR, (256, 256))\n","        image_rgb_LR = image_slice(image_rgb_LR, (128, 128)) #이미지 크기\n","        for image_SR in image_rgb_SR:\n","          all_img_SR.append(image_SR)\n","\n","\n","        for image_LR in image_rgb_LR:\n","          all_img_LR.append(image_LR)\n","\n","\n","        del image_rgb_SR\n","        del image_rgb_LR\n","  \n","  length = len(all_img_LR)\n","  length = length // global_batch_size\n","  all_img_SR = np.array(all_img_SR)\n","  all_img_LR = np.array(all_img_LR)\n","  return all_img_LR, all_img_SR, length"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yURnZKEIzA5N"},"outputs":[],"source":["BATCH_SIZE_PER_REPLICA = 1\n","global_batch_size = (BATCH_SIZE_PER_REPLICA *\n","                     strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"du2TGK0LO1Qc"},"outputs":[],"source":["def loss_function(y_true, y_pred): \n","  loss = tf.keras.losses.MAE(y_true, y_pred)\n","\n","  return loss"]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/ColabNotebooks/project/super_resolution/save_weights/new_swin_ir_64_save_weights.h5'"],"metadata":{"id":"LxShMpSO3S9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3JsAvW6mPzYl"},"outputs":[],"source":["with strategy.scope():\n","  model = swinir.swinIR(IMG_SIZE, PATCH_SIZE, IN_CHANS, EMB_SIZE, DEPTHS, NUM_HEADS, WINDOW_SIZE, MLP_RATIO, QKV_BIAS, DROP_RATE, ATTN_DROP_RATE, DROP_PATH_RATE, APE, PATCH_NORM, UPSCALE, IMG_RANGE, RESI_CONNECTION)\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","  training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n","  \n","  x = tf.random.normal(shape=(1, 64, 64, 3))\n","  output = model(x)\n","  model.load_weights(path)"]},{"cell_type":"markdown","source":["# training\n","한 번에 모든 데이터를 불러와서 학습하기에는 학습 데이터가 너무 많고 ram이 부족함.<br>\n","따라서 데이터를 나누어서 가져온 뒤 그 데이터를 삭제하고, 다음 데이터를 불러오는 방식을 사용함."],"metadata":{"id":"Ygeurc9opMOS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I500BPy9P062"},"outputs":[],"source":["def train_step(inputs):\n","  all_img_LR, all_img_SR = inputs\n","  all_img_LR = tf.cast(all_img_LR, dtype=tf.float32)\n","  with tf.GradientTape() as tape:\n","    logits = model(all_img_LR, training=True)\n","    loss = loss_function(all_img_SR, logits)\n","\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","  del all_img_LR, all_img_SR, logits\n","\n","  return loss \n","\n","@tf.function\n","def distributed_train_step(inputs):\n","  per_replica_losses = strategy.run(train_step, args=(inputs,))\n","  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n","                         axis=None)\n","  \n","for epoch in range(13, len(accl)):\n","  all_img_LR, all_img_SR, length = dataload_function(epoch, accl, danbooru_path, danbooru_list) \n","  total_loss = 0.0\n","  step_loss = 0.0\n","  num_batch = 0\n","\n","  with tqdm(total=length, desc=f\"Train_file_number({epoch})\") as pbar:\n","    for input_len in range(length):\n","      dataset = tf.data.Dataset.from_tensor_slices((\n","          all_img_LR[input_len * global_batch_size : (input_len * global_batch_size) + global_batch_size], all_img_SR[input_len * global_batch_size : (input_len * global_batch_size) + global_batch_size]\n","      )) #ram 절약을 위해 하나씩만 담음\n","      dataset = dataset.cache()\n","      dataset = dataset.batch(global_batch_size)\n","      dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","      dataset = strategy.experimental_distribute_dataset(dataset)\n","\n","      for x in dataset:\n","        step_loss = distributed_train_step(x)\n","        total_loss += tf.reduce_mean(step_loss)\n","        num_batch += 1\n","\n","      pbar.update(1)\n","\n","      if num_batch % 400 == 99:\n","        print(f\"epoch: {epoch}, step: {num_batch}, loss:{total_loss / num_batch}\")\n","        model.save_weights(path, overwrite=True) #model이 크기 때문에 학습 중간 중간에 모델 weights를 저장\n","\n","  print(f\"epoch: {epoch}, loss: {total_loss / num_batch}\")\n","\n","  del all_img_LR\n","  del all_img_SR\n","\n","  model.save_weights(path, overwrite=True)"]}]}